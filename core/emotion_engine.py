"""
æƒ…ç»ªè¯†åˆ«å¼•æ“ä¸»æ¨¡å—
æ•´åˆæ‰€æœ‰å­æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€æ¥å£
"""

import yaml
import numpy as np
from typing import Dict, List, Optional
from datetime import datetime
from pathlib import Path

from core.emotion_extractor import EmotionExtractor, EmotionFeatures
from routing.intelligent_router import IntelligentRouter, RouteLevel
from intervention.dbt_intervention import RiskAssessmentEngine
from profile.emotion_profile import EmotionProfileManager, EmotionSnapshot
from profile.advanced_emotion_profile import AdvancedEmotionProfileManager, AdvancedEmotionProfile, EmotionSnapshot as AdvancedEmotionSnapshot
from loguru import logger


class EmotionRecognitionEngine:
    """æƒ…ç»ªè¯†åˆ«å¼•æ“ä¸»ç±»"""

    def __init__(self, config_path: str = "config.yaml", use_advanced_profile: bool = True):
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

        # åˆå§‹åŒ–å„æ¨¡å—
        logger.info("åˆå§‹åŒ–æƒ…ç»ªè¯†åˆ«å¼•æ“...")

        self.extractor = EmotionExtractor(self.config)
        self.router = IntelligentRouter(self.config)
        self.risk_engine = RiskAssessmentEngine(self.config)

        # é€‰æ‹©ç”»åƒç®¡ç†å™¨ï¼ˆé«˜çº§ç‰ˆ or åŸºç¡€ç‰ˆï¼‰
        self.use_advanced_profile = use_advanced_profile
        if use_advanced_profile:
            self.profile_manager = AdvancedEmotionProfileManager(self.config)
            logger.info("ä½¿ç”¨é«˜çº§æƒ…ç»ªç”»åƒç³»ç»Ÿ")
        else:
            self.profile_manager = EmotionProfileManager(self.config)
            logger.info("ä½¿ç”¨åŸºç¡€æƒ…ç»ªç”»åƒç³»ç»Ÿ")

        # å¯¹è¯å†å²ï¼ˆç”¨äºä¸Šä¸‹æ–‡åˆ†æï¼‰
        self.conversation_history = {}

        logger.info("æƒ…ç»ªè¯†åˆ«å¼•æ“åˆå§‹åŒ–å®Œæˆ")

    def analyze(self, text: str,
                user_id: str,
                audio_path: Optional[str] = None,
                audio_data: Optional[Dict] = None,
                video_path: Optional[str] = None,
                video_data: Optional[np.ndarray] = None,
                context: str = "") -> Dict:
        """
        å®Œæ•´çš„æƒ…ç»ªåˆ†ææµç¨‹

        Args:
            text: è¾“å…¥æ–‡æœ¬
            user_id: ç”¨æˆ·ID
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            audio_data: éŸ³é¢‘æ•°æ®å­—å…¸ï¼ˆå¯é€‰ï¼‰åŒ…å«'data'å’Œ'sample_rate'
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            video_data: è§†é¢‘æ•°æ®å¸§ï¼ˆå¯é€‰ï¼‰numpyæ•°ç»„
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰

        Returns:
            å®Œæ•´çš„åˆ†æç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹åˆ†æç”¨æˆ· {user_id} çš„æƒ…ç»ªçŠ¶æ€")

        # 1. æå–æƒ…ç»ªç‰¹å¾
        logger.info("æ­¥éª¤1: æå–æƒ…ç»ªç‰¹å¾")
        features = self.extractor.extract(
            text=text,
            audio_path=audio_path,
            audio_data=audio_data,
            video_path=video_path,
            frame=video_data
        )

        # 1.5 èåˆå›¾åƒæƒ…ç»ªåˆ°text_emotionï¼ˆç”¨äºçº¯å›¾åƒè¾“å…¥çš„æƒ…å†µï¼‰
        if features.video_features:
            # æ£€æŸ¥video_featuresä¸­æ˜¯å¦åŒ…å«DBTæƒ…ç»ª
            dbt_emotions = self.extractor.dbt_emotions
            video_emotions = {k: v for k, v in features.video_features.items()
                            if k in dbt_emotions and v > 0}

            # å¦‚æœå›¾åƒæœ‰æ˜æ˜¾çš„æƒ…ç»ªåˆ†æ•°ï¼Œä¸”æ–‡æœ¬æ˜¯å ä½ç¬¦æˆ–ä¸­æ€§
            if video_emotions and sum(video_emotions.values()) > 0.3:
                if text in ["[å›¾åƒè¾“å…¥]", "[IMAGE_INPUT]", ""] or \
                   all(v == 0 for v in features.text_emotion.values()):
                    # å°†å›¾åƒæƒ…ç»ªèåˆåˆ°text_emotionä¸­
                    for emotion, score in video_emotions.items():
                        features.text_emotion[emotion] = max(
                            features.text_emotion.get(emotion, 0),
                            score * 0.8  # å›¾åƒæƒ…ç»ªæƒé‡0.8
                        )
                    logger.info(f"èåˆå›¾åƒæƒ…ç»ªåˆ°text_emotion: {video_emotions}")

        # 2. æ™ºèƒ½è·¯ç”±
        logger.info("æ­¥éª¤2: æ‰§è¡Œæ™ºèƒ½è·¯ç”±")
        route_result = self.router.route(
            text=text,
            emotion_features=features.text_emotion,
            audio_features=features.audio_features,
            video_features=features.video_features
        )

        # 3. è®¡ç®—æƒ…ç»ªæ–œç‡
        if user_id not in self.conversation_history:
            self.conversation_history[user_id] = []

        emotion_slope = self.router.calculate_emotion_slope(
            self.conversation_history[user_id]
        )

        # 4. åˆ†æå¯¹è¯ä¸Šä¸‹æ–‡
        conversation_context = self.router.analyze_conversation_context(
            self.conversation_history[user_id]
        )

        # 5. é£é™©è¯„ä¼°
        logger.info("æ­¥éª¤3: è¯„ä¼°é£é™©ç­‰çº§")
        intervention_trigger = self.risk_engine.evaluate_risk(
            emotion_features=features.text_emotion,
            emotion_slope=emotion_slope,
            conversation_context=conversation_context
        )

        # 6. åŠ è½½æˆ–åˆ›å»ºç”¨æˆ·ç”»åƒ
        logger.info("æ­¥éª¤4: æ›´æ–°ç”¨æˆ·ç”»åƒ")
        profile = self.profile_manager.load_profile(user_id)
        if profile is None:
            profile = self.profile_manager.create_profile(user_id)

        # åˆ›å»ºæƒ…ç»ªå¿«ç…§ï¼ˆæ ¹æ®ç”»åƒç±»å‹é€‰æ‹©ï¼‰
        if self.use_advanced_profile:
            # é«˜çº§å¿«ç…§ - åŒ…å«æ›´å¤šå…ƒæ•°æ®
            snapshot = AdvancedEmotionSnapshot(
                timestamp=datetime.now().timestamp(),
                date=datetime.now().isoformat(),
                emotions=features.text_emotion,
                arousal=features.text_arousal,
                route_level=route_result.level.value,
                risk_level=intervention_trigger.risk_level.value,
                context=context,
                multimodal_vector=features.multimodal_vector.tolist(),
                input_type=self._detect_input_type(text, audio_path, video_data),
                time_of_day="",  # ä¼šåœ¨profile updateä¸­å¡«å……
                day_of_week="",  # ä¼šåœ¨profile updateä¸­å¡«å……
                is_weekend=False  # ä¼šåœ¨profile updateä¸­å¡«å……
            )
        else:
            # åŸºç¡€å¿«ç…§
            snapshot = EmotionSnapshot(
                timestamp=datetime.now().timestamp(),
                date=datetime.now().isoformat(),
                emotions=features.text_emotion,
                arousal=features.text_arousal,
                route_level=route_result.level.value,
                risk_level=intervention_trigger.risk_level.value,
                context=context,
                multimodal_vector=features.multimodal_vector.tolist()
            )

        # æ›´æ–°ç”»åƒ
        self.profile_manager.update_profile(
            profile=profile,
            emotion_snapshot=snapshot,
            route_level=route_result.level.value,
            risk_level=intervention_trigger.risk_level.value
        )

        # 7. è®°å½•å¯¹è¯å†å²
        self.conversation_history[user_id].append({
            'timestamp': datetime.now().timestamp(),
            'text': text,
            'emotions': features.text_emotion.copy()
        })

        # é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history[user_id]) > 50:
            self.conversation_history[user_id].pop(0)

        # 8. æ„å»ºè¿”å›ç»“æœ
        result = {
            'user_id': user_id,
            'timestamp': datetime.now().isoformat(),

            # æƒ…ç»ªç‰¹å¾
            'emotion_features': {
                'emotions': features.text_emotion,
                'arousal': features.text_arousal,
                'confidence': features.confidence,
                'audio_features': features.audio_features,
                'video_features': features.video_features
            },

            # è·¯ç”±å†³ç­–
            'routing_decision': {
                'level': route_result.level.value,
                'reason': route_result.reason,
                'suggested_action': route_result.suggested_action,
                'requires_dbt': route_result.requires_dbt,
                'crisis_flag': route_result.crisis_flag
            },

            # å¹²é¢„è¯„ä¼°
            'intervention_assessment': {
                'triggered': intervention_trigger.triggered,
                'risk_level': intervention_trigger.risk_level.value,
                'urgency_score': intervention_trigger.urgency_score,
                'trigger_signals': intervention_trigger.trigger_signals,
                'intervention_reason': intervention_trigger.intervention_reason
            },

            # ä¸Šä¸‹æ–‡åˆ†æ
            'context_analysis': {
                'emotion_slope': emotion_slope,
                'conversation_patterns': conversation_context
            },

            # ç”»åƒæ›´æ–°
            'profile_updated': True,
            'baseline_emotions': profile.emotion_baseline if self.use_advanced_profile else profile.baseline_emotions,
            'stability_score': profile.emotion_patterns.get('stability_score', 0.5) if hasattr(profile, 'emotion_patterns') else 0.5,

            # ç³»ç»Ÿå»ºè®®
            'recommendations': self._generate_recommendations(
                route_result, intervention_trigger, profile
            )
        }

        logger.info(f"åˆ†æå®Œæˆ - è·¯ç”±çº§åˆ«: {route_result.level.value}, é£é™©ç­‰çº§: {intervention_trigger.risk_level.value}")

        return result

    def _generate_recommendations(self, route_result, intervention_trigger, profile) -> List[str]:
        """ç”Ÿæˆç³»ç»Ÿå»ºè®®"""
        recommendations = []

        # æ ¹æ®è·¯ç”±çº§åˆ«
        if route_result.level == RouteLevel.L3_CRISIS:
            recommendations.append("ğŸš¨ ç«‹å³å¯åŠ¨å±æœºå¹²é¢„ç¨‹åº")
            recommendations.append("ğŸ“ è”ç³»ç´§æ€¥è”ç³»äººæˆ–ä¸“ä¸šå¸®åŠ©")
            recommendations.append("âš ï¸ ä¸è¦è®©ç”¨æˆ·ç‹¬å¤„")
        elif route_result.level == RouteLevel.L2_INTERVENTION:
            recommendations.append("ğŸ’¡ å»ºè®®å¯ç”¨DBTæŠ€èƒ½æ”¯æŒï¼ˆæ¨¡å—2ï¼‰")
            recommendations.append(f"ğŸ“Š é£é™©ä¿¡å·: {intervention_trigger.trigger_signals}")
        else:
            recommendations.append("âœ… ç»§ç»­æ—¥å¸¸å¯¹è¯æ”¯æŒ")

        # æ ¹æ®é£é™©ç­‰çº§
        if intervention_trigger.risk_level.value in ['HIGH', 'CRITICAL']:
            recommendations.append("â° å®‰æ’åç»­è·Ÿè¿›")
            recommendations.append("ğŸ‘¥ è€ƒè™‘é€šçŸ¥æ”¯æŒç½‘ç»œ")

        # æ ¹æ®ç”»åƒç‰¹å¾
        typical_response = None
        if self.use_advanced_profile and hasattr(profile, 'emotion_clusters'):
            # ä»èšç±»ä¸­æ¨æ–­å…¸å‹ååº”
            if profile.emotion_clusters:
                cluster_name = profile.emotion_clusters[0].cluster_name
                if 'anger' in cluster_name.lower() or 'rage' in cluster_name.lower():
                    typical_response = 'anger'
                elif 'sad' in cluster_name.lower() or 'withdraw' in cluster_name.lower():
                    typical_response = 'withdrawal'

        if not typical_response and hasattr(profile, 'emotion_patterns'):
            typical_response = profile.emotion_patterns.get('typical_response')

        if typical_response == 'withdrawal':
            recommendations.append("ğŸ¤— ç”¨æˆ·å€¾å‘äºé€€ç¼©ï¼Œç»™äºˆæ¸©å’Œæ”¯æŒ")
        elif typical_response == 'anger':
            recommendations.append("ğŸ˜¤ ç”¨æˆ·å€¾å‘äºæ„¤æ€’ï¼Œæ¥çº³å¹¶è®¤å¯æ„Ÿå—")

        # ç—…ç†æ€§ç‰¹å¾è­¦å‘Š
        if self.use_advanced_profile:
            # é«˜çº§ç”»åƒæœ‰å†…ç½®çš„é£é™©é¢„æµ‹
            if profile.risk_prediction and profile.risk_prediction.early_warning_signals:
                recommendations.append("âš ï¸ æ£€æµ‹åˆ°æ—©æœŸé¢„è­¦ä¿¡å·ï¼Œå»ºè®®å¯†åˆ‡å…³æ³¨")
        else:
            pathological = self.profile_manager.detect_pathological_features(profile)
            if pathological:
                recommendations.append("âš ï¸ å»ºè®®å¯»æ±‚ä¸“ä¸šå¿ƒç†å’¨è¯¢")

        return recommendations

    def get_profile(self, user_id: str) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ç”»åƒ"""
        profile = self.profile_manager.load_profile(user_id)
        if profile is None:
            return None

        if self.use_advanced_profile:
            # é«˜çº§ç”»åƒ
            return {
                'raw_profile': profile,
                'report': self.profile_manager.generate_profile_report(profile),
                'self_agent_export': self.profile_manager.export_for_self_agent(profile)
            }
        else:
            # åŸºç¡€ç”»åƒ
            return {
                'summary': self.profile_manager.get_profile_summary(profile),
                'self_agent_params': self.profile_manager.export_for_self_agent(profile),
                'pathological_indicators': self.profile_manager.detect_pathological_features(profile)
            }

    def generate_profile_report(self, user_id: str) -> Optional[str]:
        """ç”Ÿæˆè¯¦ç»†çš„ç”¨æˆ·ç”»åƒæŠ¥å‘Š"""
        if not self.use_advanced_profile:
            logger.warning("ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šéœ€è¦å¯ç”¨é«˜çº§ç”»åƒç³»ç»Ÿ (use_advanced_profile=True)")
            return None

        profile = self.profile_manager.load_profile(user_id)
        if profile is None:
            logger.warning(f"ç”¨æˆ·ç”»åƒä¸å­˜åœ¨: {user_id}")
            return None

        return self.profile_manager.generate_profile_report(profile)

    def _detect_input_type(self, text: str, audio_path: Optional[str], video_data: Optional[np.ndarray]) -> str:
        """æ£€æµ‹è¾“å…¥ç±»å‹"""
        if video_data is not None:
            return "image"
        elif audio_path is not None:
            return "audio"
        elif text and text not in ["[å›¾åƒè¾“å…¥]", "[IMAGE_INPUT]", "[è§†é¢‘è¾“å…¥]", ""]:
            return "text"
        else:
            return "unknown"

    def reset_user_history(self, user_id: str):
        """é‡ç½®ç”¨æˆ·å†å²ï¼ˆæµ‹è¯•ç”¨ï¼‰"""
        if user_id in self.conversation_history:
            self.conversation_history[user_id] = []
        logger.info(f"é‡ç½®ç”¨æˆ· {user_id} çš„å†å²è®°å½•")

    def batch_analyze(self, texts: List[str], user_id: str) -> List[Dict]:
        """æ‰¹é‡åˆ†æï¼ˆç”¨äºæ•°æ®å¤„ç†ï¼‰"""
        results = []
        for text in texts:
            result = self.analyze(text=text, user_id=user_id)
            results.append(result)
        return results

    def get_system_stats(self) -> Dict:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        # ç»Ÿè®¡profilesç›®å½•ä¸‹çš„ç”¨æˆ·æ•°
        profiles_dir = Path("profiles")
        user_count = len(list(profiles_dir.glob("*.json"))) if profiles_dir.exists() else 0

        return {
            'total_users': user_count,
            'tracked_users': len(self.conversation_history),
            'engine_type': 'risk_assessment',
            'model_status': 'remote_api' if self.extractor.api_key else 'local_rules'
        }
