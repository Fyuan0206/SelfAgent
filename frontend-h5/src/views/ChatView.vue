<script setup lang="ts">
import { ref, nextTick, onMounted, onUnmounted } from 'vue'
import { useRouter } from 'vue-router'
import { useChatStore } from '@/stores/chat'
import { useAppStore } from '@/stores/app'
import { sendTextMessage, sendMultimodalMessage } from '@/api/chat'
import { showToast } from 'vant'

const router = useRouter()
const chatStore = useChatStore()
const appStore = useAppStore()

const messageInput = ref('')
const messagesContainer = ref<HTMLElement | null>(null)
const fileInput = ref<HTMLInputElement | null>(null)
const selectedFile = ref<File | null>(null)

// Voice recording state
const isRecording = ref(false)
const recordingTime = ref(0)
const mediaRecorder = ref<MediaRecorder | null>(null)
const audioChunks = ref<Blob[]>([])
let recordingTimer: number | null = null

// Camera state
const isCameraOpen = ref(false)
const videoRef = ref<HTMLVideoElement | null>(null)
const cameraStream = ref<MediaStream | null>(null)
const currentEmotion = ref({ name: 'åˆ†æä¸­...', confidence: 0, videoEmotion: '', audioEmotion: '' })
const cameraAudioRecorder = ref<MediaRecorder | null>(null)
const cameraAudioChunks = ref<Blob[]>([])
let analysisInterval: number | null = null

const emotionTags = [
  { label: 'ğŸ˜Š å¼€å¿ƒ', value: 'å¼€å¿ƒ', color: 'bg-yellow-100 text-yellow-700' },
  { label: 'ğŸ˜° ç„¦è™‘', value: 'ç„¦è™‘', color: 'bg-blue-100 text-blue-700' },
  { label: 'ğŸ˜¢ éš¾è¿‡', value: 'éš¾è¿‡', color: 'bg-gray-100 text-gray-700' },
  { label: 'ğŸ˜  æ„¤æ€’', value: 'æ„¤æ€’', color: 'bg-red-100 text-red-700' },
]

const scrollToBottom = async () => {
  await nextTick()
  if (messagesContainer.value) {
    messagesContainer.value.scrollTop = messagesContainer.value.scrollHeight
  }
}

// Voice recording functions
const startRecording = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    mediaRecorder.value = new MediaRecorder(stream)
    audioChunks.value = []

    mediaRecorder.value.ondataavailable = (e) => {
      if (e.data.size > 0) audioChunks.value.push(e.data)
    }

    mediaRecorder.value.onstop = () => {
      stream.getTracks().forEach(track => track.stop())
      if (audioChunks.value.length > 0 && recordingTime.value >= 1) {
        const audioBlob = new Blob(audioChunks.value, { type: 'audio/webm' })
        const audioFile = new File([audioBlob], `voice_${Date.now()}.webm`, { type: 'audio/webm' })
        selectedFile.value = audioFile
        sendMessage()
      }
    }

    mediaRecorder.value.start()
    isRecording.value = true
    recordingTime.value = 0
    recordingTimer = window.setInterval(() => {
      recordingTime.value++
    }, 1000)
  } catch (e) {
    showToast('æ— æ³•è®¿é—®éº¦å…‹é£')
  }
}

const stopRecording = () => {
  if (mediaRecorder.value && isRecording.value) {
    mediaRecorder.value.stop()
    isRecording.value = false
    if (recordingTimer) {
      clearInterval(recordingTimer)
      recordingTimer = null
    }
  }
}

const cancelRecording = () => {
  if (mediaRecorder.value && isRecording.value) {
    mediaRecorder.value.stop()
    audioChunks.value = []
    isRecording.value = false
    if (recordingTimer) {
      clearInterval(recordingTimer)
      recordingTimer = null
    }
    showToast('å·²å–æ¶ˆå½•éŸ³')
  }
}

// Camera functions
const openCamera = async () => {
  try {
    // åŒæ—¶è·å–è§†é¢‘å’ŒéŸ³é¢‘
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'user', width: 320, height: 240 },
      audio: true
    })
    cameraStream.value = stream
    isCameraOpen.value = true

    await nextTick()
    if (videoRef.value) {
      videoRef.value.srcObject = stream
      videoRef.value.play()
    }

    // è®¾ç½®éŸ³é¢‘å½•åˆ¶å™¨
    const audioTracks = stream.getAudioTracks()
    if (audioTracks.length > 0) {
      const audioStream = new MediaStream(audioTracks)
      cameraAudioRecorder.value = new MediaRecorder(audioStream)
      cameraAudioChunks.value = []

      cameraAudioRecorder.value.ondataavailable = (e) => {
        if (e.data.size > 0) {
          cameraAudioChunks.value.push(e.data)
        }
      }

      // æ¯2ç§’æ”¶é›†ä¸€æ¬¡éŸ³é¢‘æ•°æ®
      cameraAudioRecorder.value.start(2000)
    }

    // Start emotion analysis every 2 seconds
    analysisInterval = window.setInterval(analyzeFrame, 2000)
    showToast('æ‘„åƒå¤´å·²å¼€å¯')
  } catch (e) {
    showToast('æ— æ³•è®¿é—®æ‘„åƒå¤´')
    console.error(e)
  }
}

const closeCamera = () => {
  // åœæ­¢éŸ³é¢‘å½•åˆ¶
  if (cameraAudioRecorder.value && cameraAudioRecorder.value.state !== 'inactive') {
    cameraAudioRecorder.value.stop()
    cameraAudioRecorder.value = null
  }
  cameraAudioChunks.value = []

  if (cameraStream.value) {
    cameraStream.value.getTracks().forEach(track => track.stop())
    cameraStream.value = null
  }
  if (analysisInterval) {
    clearInterval(analysisInterval)
    analysisInterval = null
  }
  isCameraOpen.value = false
  currentEmotion.value = { name: 'åˆ†æä¸­...', confidence: 0, videoEmotion: '', audioEmotion: '' }
}

const toggleCamera = () => {
  if (isCameraOpen.value) {
    closeCamera()
  } else {
    openCamera()
  }
}

const analyzeFrame = async () => {
  if (!videoRef.value || !cameraStream.value) return

  try {
    // è·å–è§†é¢‘å¸§
    const canvas = document.createElement('canvas')
    canvas.width = videoRef.value.videoWidth || 320
    canvas.height = videoRef.value.videoHeight || 240
    const ctx = canvas.getContext('2d')
    if (ctx) {
      ctx.drawImage(videoRef.value, 0, 0)
    }

    const videoBlob = await new Promise<Blob | null>(resolve => {
      canvas.toBlob(resolve, 'image/jpeg', 0.8)
    })

    // è·å–éŸ³é¢‘æ•°æ®
    let audioBlob: Blob | null = null
    if (cameraAudioChunks.value.length > 0) {
      audioBlob = new Blob(cameraAudioChunks.value, { type: 'audio/webm' })
      cameraAudioChunks.value = [] // æ¸…ç©ºå·²å¤„ç†çš„éŸ³é¢‘
    }

    let videoResult: any = null
    let audioResult: any = null

    if (videoBlob) {
      // å‘é€è§†é¢‘å¸§åˆ†æ
      const videoFile = new File([videoBlob], 'frame.jpg', { type: 'image/jpeg' })
      videoResult = await sendMultimodalMessage(chatStore.userId, '(å®æ—¶è§†é¢‘åˆ†æ)', videoFile)
    }

    // å‘é€éŸ³é¢‘åˆ†æï¼ˆå¦‚æœæœ‰éŸ³é¢‘æ•°æ®ï¼‰
    if (audioBlob && audioBlob.size > 0) {
      const audioFile = new File([audioBlob], 'audio.webm', { type: 'audio/webm' })
      audioResult = await sendMultimodalMessage(chatStore.userId, '(å®æ—¶éŸ³é¢‘åˆ†æ)', audioFile)
    }

    // è§£æåç«¯è¿”å›çš„æƒ…ç»ªæ•°æ®
    const videoEmotion = videoResult?.emotion?.name || 'æœªçŸ¥'
    const videoConf = videoResult?.emotion?.confidence || 0
    const audioEmotion = audioResult?.emotion?.name || 'æ— éŸ³é¢‘'
    const audioConf = audioResult?.emotion?.confidence || 0

    // ç»¼åˆæƒ…ç»ªï¼ˆå–ç½®ä¿¡åº¦è¾ƒé«˜çš„ï¼‰
    let finalEmotion: string
    let finalConf: number
    if (audioConf > videoConf && audioResult) {
      finalEmotion = audioEmotion
      finalConf = audioConf
    } else {
      finalEmotion = videoEmotion
      finalConf = videoConf
    }

    currentEmotion.value = {
      name: finalEmotion,
      confidence: finalConf,
      videoEmotion: `${videoEmotion} ${videoConf.toFixed(0)}%`,
      audioEmotion: audioResult ? `${audioEmotion} ${audioConf.toFixed(0)}%` : 'æ— éŸ³é¢‘'
    }
  } catch (e) {
    console.error('Analysis failed:', e)
  }
}

const sendMessage = async () => {
  const text = messageInput.value.trim()
  if (!text && !selectedFile.value) return

  // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
  chatStore.addMessage({
    role: 'user',
    content: text || '(å‘é€äº†æ–‡ä»¶)',
    file: selectedFile.value ? {
      type: selectedFile.value.type.startsWith('audio') ? 'audio' : 'image',
      name: selectedFile.value.name,
      url: URL.createObjectURL(selectedFile.value)
    } : undefined
  })

  messageInput.value = ''
  chatStore.setLoading(true)
  scrollToBottom()

  try {
    let response
    if (selectedFile.value) {
      response = await sendMultimodalMessage(
        chatStore.userId,
        text,
        selectedFile.value
      )
    } else {
      response = await sendTextMessage({
        user_id: chatStore.userId,
        text: text
      })
    }

    chatStore.addMessage({
      role: 'assistant',
      content: response.response,
      emotion: response.emotion?.name
    })

    if (response.emotion) {
      chatStore.updateEmotion({
        name: response.emotion.name,
        value: response.emotion.intensity,
        color: getEmotionColor(response.emotion.name)
      })
    }
  } catch (error) {
    showToast('å‘é€å¤±è´¥ï¼Œè¯·é‡è¯•')
    console.error(error)
  } finally {
    chatStore.setLoading(false)
    selectedFile.value = null
    scrollToBottom()
  }
}

const quickEmotion = (emotion: string) => {
  messageInput.value = `æˆ‘ç°åœ¨æ„Ÿè§‰${emotion}`
}

const handleFileSelect = (event: Event) => {
  const target = event.target as HTMLInputElement
  if (target.files && target.files[0]) {
    selectedFile.value = target.files[0]
    showToast(`å·²é€‰æ‹©: ${target.files[0].name}`)
  }
}

const getEmotionColor = (emotion: string): string => {
  const colors: Record<string, string> = {
    'å¼€å¿ƒ': '#22c55e',
    'å¹³é™': '#22c55e',
    'ç„¦è™‘': '#3b82f6',
    'éš¾è¿‡': '#6b7280',
    'æ„¤æ€’': '#ef4444',
    'ææƒ§': '#8b5cf6',
  }
  return colors[emotion] || '#6366f1'
}

const formatTime = (date: Date) => {
  return new Date(date).toLocaleTimeString('zh-CN', {
    hour: '2-digit',
    minute: '2-digit'
  })
}

onMounted(() => {
  scrollToBottom()
})

onUnmounted(() => {
  if (recordingTimer) clearInterval(recordingTimer)
  if (analysisInterval) clearInterval(analysisInterval)
  closeCamera()
})
</script>

<template>
  <div class="flex flex-col h-screen pb-14">
    <!-- æ‘„åƒå¤´æ‚¬æµ®çª— -->
    <div
      v-if="isCameraOpen"
      class="fixed top-16 right-2 z-40 bg-white dark:bg-slate-800 rounded-xl shadow-lg overflow-hidden"
      style="width: 160px;"
    >
      <div class="flex items-center justify-between px-2 py-1 bg-indigo-500 text-white text-xs">
        <span>å®æ—¶æƒ…ç»ªåˆ†æ</span>
        <van-icon name="cross" size="14" @click="closeCamera" />
      </div>
      <video
        ref="videoRef"
        class="w-full h-24 object-cover bg-black"
        autoplay
        playsinline
        muted
      ></video>
      <div class="p-2 text-xs">
        <div class="flex items-center justify-between mb-1">
          <span class="text-gray-600 dark:text-gray-400">ç»¼åˆ:</span>
          <span class="font-medium text-indigo-600">{{ currentEmotion.name }} {{ currentEmotion.confidence }}%</span>
        </div>
        <div class="w-full bg-gray-200 dark:bg-slate-600 rounded-full h-1.5 mb-1">
          <div
            class="bg-indigo-500 h-1.5 rounded-full transition-all"
            :style="{ width: `${currentEmotion.confidence}%` }"
          ></div>
        </div>
        <div class="text-gray-400 text-[10px]">
          <div>è§†é¢‘: {{ currentEmotion.videoEmotion || '-' }}</div>
          <div>éŸ³é¢‘: {{ currentEmotion.audioEmotion || '-' }}</div>
        </div>
      </div>
    </div>

    <!-- é¡¶éƒ¨æ  -->
    <div class="glass border-b border-gray-200/50 px-4 py-3 safe-area-top">
      <div class="flex items-center justify-between">
        <div class="flex items-center gap-3">
          <div class="w-10 h-10 rounded-full gradient-bg flex items-center justify-center shadow">
            <van-icon name="service-o" color="white" size="20" />
          </div>
          <div>
            <h1 class="text-base font-semibold text-gray-900 dark:text-white">Self-Agent</h1>
            <p class="text-xs text-gray-500">åœ¨çº¿ Â· éšæ—¶ä¸ºæ‚¨æä¾›æ”¯æŒ</p>
          </div>
        </div>
        <div class="flex items-center gap-2">
          <van-button
            size="small"
            type="danger"
            round
            class="crisis-pulse"
            @click="router.push('/crisis')"
          >
            <van-icon name="warning-o" />
            ç´§æ€¥
          </van-button>
        </div>
      </div>
    </div>

    <!-- æ¶ˆæ¯åŒºåŸŸ -->
    <div
      ref="messagesContainer"
      class="flex-1 overflow-y-auto px-4 py-4 space-y-4"
    >
      <div
        v-for="message in chatStore.messages"
        :key="message.id"
        class="message-enter"
        :class="message.role === 'user' ? 'flex justify-end' : 'flex justify-start'"
      >
        <!-- AI æ¶ˆæ¯ -->
        <div v-if="message.role === 'assistant'" class="flex items-start gap-2 max-w-[85%]">
          <div class="w-8 h-8 rounded-full gradient-bg flex items-center justify-center flex-shrink-0">
            <van-icon name="service-o" color="white" size="16" />
          </div>
          <div>
            <div class="bg-white dark:bg-slate-700 rounded-2xl rounded-tl-sm px-4 py-3 shadow-sm">
              <p class="text-gray-800 dark:text-gray-100 text-sm whitespace-pre-wrap">{{ message.content }}</p>
            </div>
            <span class="text-xs text-gray-400 mt-1 ml-2">{{ formatTime(message.timestamp) }}</span>
          </div>
        </div>

        <!-- ç”¨æˆ·æ¶ˆæ¯ -->
        <div v-else class="flex items-start gap-2 max-w-[85%] flex-row-reverse">
          <div class="w-8 h-8 rounded-full bg-primary-500 flex items-center justify-center flex-shrink-0">
            <van-icon name="user-o" color="white" size="16" />
          </div>
          <div class="text-right">
            <div class="bg-primary-500 text-white rounded-2xl rounded-tr-sm px-4 py-3 shadow-sm">
              <p class="text-sm whitespace-pre-wrap">{{ message.content }}</p>
              <div v-if="message.file" class="mt-2 text-xs opacity-80">
                ğŸ“ {{ message.file.name }}
              </div>
            </div>
            <span class="text-xs text-gray-400 mt-1 mr-2">{{ formatTime(message.timestamp) }}</span>
          </div>
        </div>
      </div>

      <!-- åŠ è½½æŒ‡ç¤ºå™¨ -->
      <div v-if="chatStore.isLoading" class="flex items-start gap-2">
        <div class="w-8 h-8 rounded-full gradient-bg flex items-center justify-center">
          <van-icon name="service-o" color="white" size="16" />
        </div>
        <div class="bg-white dark:bg-slate-700 rounded-2xl px-4 py-3 shadow-sm">
          <div class="flex gap-1">
            <span class="typing-dot w-2 h-2 bg-gray-400 rounded-full"></span>
            <span class="typing-dot w-2 h-2 bg-gray-400 rounded-full"></span>
            <span class="typing-dot w-2 h-2 bg-gray-400 rounded-full"></span>
          </div>
        </div>
      </div>
    </div>

    <!-- è¾“å…¥åŒºåŸŸ -->
    <div class="glass border-t border-gray-200/50 px-4 py-3">
      <!-- å½•éŸ³çŠ¶æ€è¦†ç›–å±‚ -->
      <div
        v-if="isRecording"
        class="fixed inset-0 bg-black/60 z-50 flex flex-col items-center justify-center"
        @touchmove.prevent
      >
        <div class="w-24 h-24 rounded-full bg-red-500 flex items-center justify-center mb-4 animate-pulse">
          <van-icon name="audio" color="white" size="40" />
        </div>
        <p class="text-white text-lg mb-2">æ­£åœ¨å½•éŸ³... {{ recordingTime }}s</p>
        <p class="text-white/60 text-sm">æ¾å¼€å‘é€ï¼Œä¸Šæ»‘å–æ¶ˆ</p>
      </div>

      <!-- æƒ…ç»ªå¿«æ·æ ‡ç­¾ -->
      <div class="flex gap-2 mb-3 overflow-x-auto pb-1">
        <button
          v-for="tag in emotionTags"
          :key="tag.value"
          :class="['flex-shrink-0 px-3 py-1.5 rounded-full text-sm font-medium', tag.color]"
          @click="quickEmotion(tag.value)"
        >
          {{ tag.label }}
        </button>
      </div>

      <!-- è¾“å…¥æ§ä»¶ -->
      <div class="flex items-end gap-2">
        <input
          ref="fileInput"
          type="file"
          accept="audio/*,image/*"
          class="hidden"
          @change="handleFileSelect"
        />
        <!-- è¯­éŸ³æŒ‰é’® -->
        <van-button
          icon="audio"
          round
          size="small"
          :type="isRecording ? 'danger' : 'default'"
          @touchstart.prevent="startRecording"
          @touchend.prevent="stopRecording"
          @mousedown.prevent="startRecording"
          @mouseup.prevent="stopRecording"
          @mouseleave="isRecording && cancelRecording()"
        />
        <!-- å›¾ç‰‡æŒ‰é’® -->
        <van-button
          icon="photo-o"
          round
          size="small"
          @click="fileInput?.click()"
        />
        <!-- æ‘„åƒå¤´æŒ‰é’® -->
        <van-button
          icon="video-o"
          round
          size="small"
          :type="isCameraOpen ? 'success' : 'default'"
          @click="toggleCamera"
        />
        <van-field
          v-model="messageInput"
          type="textarea"
          rows="1"
          autosize
          placeholder="è¯´è¯´ä½ çš„æ„Ÿå—..."
          class="flex-1 !bg-gray-100 dark:!bg-slate-700 !rounded-xl"
          @keydown.enter.exact.prevent="sendMessage"
        />
        <van-button
          type="primary"
          icon="guide-o"
          round
          size="small"
          :loading="chatStore.isLoading"
          @click="sendMessage"
        />
      </div>

      <!-- æ–‡ä»¶é¢„è§ˆ -->
      <div v-if="selectedFile" class="mt-2 p-2 bg-gray-100 dark:bg-slate-700 rounded-lg flex items-center justify-between">
        <span class="text-sm text-gray-600 dark:text-gray-300 truncate">
          ğŸ“ {{ selectedFile.name }}
        </span>
        <van-button size="mini" @click="selectedFile = null">å–æ¶ˆ</van-button>
      </div>
    </div>
  </div>
</template>
